{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bb283ff-8465-48df-9f79-920894524bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import tqdm.notebook as tqdm\n",
    "import pathlib\n",
    "import statsmodels.api as sm\n",
    "import subprocess\n",
    "import shlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc7bcc9-fd14-4d39-9c17-6552546ef1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathlib.Path(\"data/pheno\").mkdir(exist_ok=True, parents=True)\n",
    "pathlib.Path(\"data/gwas\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39056eac-87e2-4f06-9484-02f54773b870",
   "metadata": {},
   "source": [
    "# Generate and format all phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f2358a-d2ff-4c30-bfbe-1f493404e3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing data\n",
      "Generated all AND phenotypes\n",
      "Generated all OR phenotypes\n",
      "Generated all MUL phenotypes\n",
      "Collected main phenotypes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc13c483af74d8681a1b1dd402bdf28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving phenotypes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 3_149)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>FID</th><th>IID</th><th>A04</th><th>A08</th><th>A09</th><th>A15</th><th>A37</th><th>A38</th><th>A41</th><th>A49</th><th>A63</th><th>B00</th><th>B01</th><th>B02</th><th>B05</th><th>B06</th><th>B07</th><th>B08</th><th>B15</th><th>B19</th><th>B26</th><th>B27</th><th>B34</th><th>B35</th><th>B36</th><th>B37</th><th>B86</th><th>B95</th><th>B96</th><th>B97</th><th>B98</th><th>B99</th><th>C15</th><th>C16</th><th>C18</th><th>C19</th><th>C20</th><th>&hellip;</th><th>anon_001_mul_G44_R91</th><th>anon_001_mul_I22_J06</th><th>anon_001_mul_W10_E55</th><th>anon_001_mul_R54_B37</th><th>anon_001_mul_L24_M05</th><th>anon_001_mul_D63_J96</th><th>anon_001_mul_E11_R68</th><th>anon_001_mul_R30_H33</th><th>anon_001_mul_A37_F34</th><th>anon_001_mul_D23_T79</th><th>anon_001_mul_D23_E06</th><th>anon_001_mul_H36_Z43</th><th>anon_001_mul_N60_Y42</th><th>anon_001_mul_R21_L81</th><th>anon_001_mul_Z11_O00</th><th>anon_001_mul_N03_E16</th><th>anon_001_mul_I24_I89</th><th>anon_001_mul_M62_L01</th><th>anon_001_mul_J02_O48</th><th>anon_001_mul_N12_T90</th><th>anon_001_mul_K29_Z42</th><th>anon_001_mul_W45_G91</th><th>anon_001_mul_M13_B01</th><th>anon_001_mul_I83_Z57</th><th>anon_001_mul_A41_D33</th><th>anon_001_mul_S63_R17</th><th>anon_001_mul_C82_N99</th><th>anon_001_mul_S27_D64</th><th>anon_001_mul_M53_I72</th><th>anon_001_mul_Z04_N10</th><th>anon_001_mul_H53_J13</th><th>anon_001_mul_M31_D51</th><th>anon_001_mul_H26_M96</th><th>anon_001_mul_Z74_Q21</th><th>anon_001_mul_T90_D48</th><th>anon_001_mul_N48_M86</th><th>anon_001_mul_R22_W29</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 3_149)\n",
       "┌─────┬─────┬─────┬─────┬───┬─────────────────┬─────────────────┬─────────────────┬────────────────┐\n",
       "│ FID ┆ IID ┆ A04 ┆ A08 ┆ … ┆ anon_001_mul_Z7 ┆ anon_001_mul_T9 ┆ anon_001_mul_N4 ┆ anon_001_mul_R │\n",
       "│ --- ┆ --- ┆ --- ┆ --- ┆   ┆ 4_Q21           ┆ 0_D48           ┆ 8_M86           ┆ 22_W29         │\n",
       "│ i64 ┆ i64 ┆ i64 ┆ i64 ┆   ┆ ---             ┆ ---             ┆ ---             ┆ ---            │\n",
       "│     ┆     ┆     ┆     ┆   ┆ f64             ┆ f64             ┆ f64             ┆ f64            │\n",
       "╞═════╪═════╪═════╪═════╪═══╪═════════════════╪═════════════════╪═════════════════╪════════════════╡\n",
       "└─────┴─────┴─────┴─────┴───┴─────────────────┴─────────────────┴─────────────────┴────────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheno_df = pl.scan_csv(\"data/pheno/original.tsv\", separator=\"\\t\")\n",
    "\n",
    "features = pheno_df.drop([\"FID\", \"IID\"]).collect_schema().names()\n",
    "pheno_df = pheno_df.with_columns(pl.col(features).sub(2))\n",
    "\n",
    "k_to_anon_pheno_df = {\n",
    "    int(path.stem.replace(\"anon_\", \"\")): (\n",
    "        pl.scan_csv(path, separator=\"\\t\")\n",
    "        .drop(\"n_occurrences\")\n",
    "        .select(pl.all().sub(2))\n",
    "    )\n",
    "    for path in pathlib.Path(\"data/pheno/\").glob(\"anon*tsv\")\n",
    "}\n",
    "k_to_anon_pheno_df[1] = (\n",
    "    pl.scan_csv(\"data/pheno/original.tsv\", separator=\"\\t\")\n",
    "    .drop([\"FID\", \"IID\"])\n",
    "    .select(pl.all().sub(2))\n",
    ")\n",
    "\n",
    "print(\"Loaded existing data\")\n",
    "\n",
    "n_per = 100\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate AND (MIN) and OR (MAX) random phenotypes\n",
    "for i in range(n_per):\n",
    "    a, b = np.random.choice(features, 2, replace=False).tolist()\n",
    "    pheno_df = (\n",
    "        pheno_df\n",
    "        .with_columns(pl.min_horizontal(pl.col(a, b)).alias(f\"and_{a}_{b}\"))\n",
    "    )\n",
    "    for k, anon_pheno_df in k_to_anon_pheno_df.items():\n",
    "        k_to_anon_pheno_df[k] = (\n",
    "            anon_pheno_df\n",
    "            .with_columns(\n",
    "                pl.min_horizontal(pl.col(a, b)).alias(f\"and_{a}_{b}\")\n",
    "            )\n",
    "        )\n",
    "            \n",
    "print(\"Generated all AND phenotypes\")\n",
    "    \n",
    "for i in range(n_per):\n",
    "    a, b = np.random.choice(features, 2, replace=False).tolist()\n",
    "    pheno_df = (\n",
    "        pheno_df\n",
    "        .with_columns(pl.max_horizontal(pl.col(a, b)).alias(f\"or_{a}_{b}\"))\n",
    "    )\n",
    "    for k, anon_pheno_df in k_to_anon_pheno_df.items():\n",
    "        k_to_anon_pheno_df[k] = (\n",
    "            anon_pheno_df\n",
    "            .with_columns(\n",
    "                pl.max_horizontal(pl.col(a, b)).alias(f\"or_{a}_{b}\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(\"Generated all OR phenotypes\")\n",
    "    \n",
    "for i in range(n_per):\n",
    "    a, b = np.random.choice(features, 2, replace=False).tolist()\n",
    "    pheno_df = (\n",
    "        pheno_df\n",
    "        .with_columns((pl.col(a) * pl.col(b)).alias(f\"mul_{a}_{b}\"))\n",
    "    )\n",
    "    for k, anon_pheno_df in k_to_anon_pheno_df.items():\n",
    "        k_to_anon_pheno_df[k] = (\n",
    "            anon_pheno_df\n",
    "            .with_columns((pl.col(a) * pl.col(b)).alias(f\"mul_{a}_{b}\"))\n",
    "        )\n",
    "\n",
    "print(\"Generated all MUL phenotypes\")\n",
    "\n",
    "pheno_df = pheno_df.collect()\n",
    "\n",
    "print(\"Collected main phenotypes\")\n",
    "\n",
    "X = pheno_df.select(\"^[A-Z][0-9]{2}$\", const=1.0).to_pandas()\n",
    "\n",
    "for k, anon_df in tqdm.tqdm(k_to_anon_pheno_df.items()):\n",
    "    anon_df = anon_df.collect()\n",
    "    X_anon = anon_df.select(\"^[A-Z][0-9]{2}$\", const=1.0).to_pandas()\n",
    "    assert sorted(X_anon.columns) == sorted(X.columns)\n",
    "    \n",
    "    Y_anon = anon_df.select(\"^(and|or|mul)_.+$\").to_pandas()\n",
    "    beta = np.linalg.lstsq(X_anon, Y_anon)[0]\n",
    "    beta_df = pd.DataFrame(beta, index=X_anon.columns, columns=Y_anon.columns)\n",
    "    this_pheno_df = (\n",
    "        (X @ beta_df)\n",
    "        .pipe(pl.DataFrame) \n",
    "        .select(pl.all().name.prefix(f\"anon_{k:03}_\"))\n",
    "    )\n",
    "    pheno_df = pl.concat([pheno_df, this_pheno_df], how=\"horizontal\")\n",
    "    \n",
    "pheno_df = (\n",
    "    pheno_df\n",
    "    .select(\"FID\", \"IID\", pl.all().exclude(\"FID\", \"IID\").add(2))\n",
    ")\n",
    "\n",
    "print(\"Saving phenotypes\")\n",
    "\n",
    "pheno_df.write_csv(\"data/pheno/full_pheno.tsv\", separator=\"\\t\")\n",
    "\n",
    "pheno_df.head(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e349b-5d50-4f3c-9ead-2146fd5b5a34",
   "metadata": {},
   "source": [
    "# Run GWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccef0c11-dfdb-48eb-9935-330840983148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v2.0.0-a.6.0LM AVX2 Intel (11 Nov 2024)      cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2024 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to data/gwas/result.log.\n",
      "Options in effect:\n",
      "  --glm zs hide-covar allow-no-covars\n",
      "  --out data/gwas/result\n",
      "  --pfile ../../data/geno/ukb_wb_subsampled\n",
      "  --pheno data/pheno/full_pheno.tsv\n",
      "  --threads 100\n",
      "\n",
      "Start time: Mon Nov 25 16:42:02 2024\n",
      "1031943 MiB RAM detected, ~964752 available; reserving 515971 MiB for main\n",
      "workspace.\n",
      "Using up to 100 threads (change this with --threads).\n",
      "429954 samples (232741 females, 197213 males; 429954 founders) loaded from\n",
      "../../data/geno/ukb_wb_subsampled.psam.\n",
      "10000 variants loaded from ../../data/geno/ukb_wb_subsampled.pvar.\n",
      "3147 phenotypes loaded (4 binary, 3143 quantitative).\n",
      "Calculating allele frequencies... done.\n",
      "--glm linear regression on quantitative phenotypes #1-240: done.\n",
      "--glm linear regression on quantitative phenotypes #241-480: done.\n",
      "--glm linear regression on quantitative phenotypes #481-720: done.\n",
      "--glm linear regression on quantitative phenotypes #721-960: done.\n",
      "--glm linear regression on quantitative phenotypes #961-1200: done.\n",
      "--glm linear regression on quantitative phenotypes #1201-1440: done.\n",
      "--glm linear regression on quantitative phenotypes #1441-1680: done.\n",
      "--glm linear regression on quantitative phenotypes #1681-1920: done.\n",
      "--glm linear regression on quantitative phenotypes #1921-2160: done.\n",
      "--glm linear regression on quantitative phenotypes #2161-2400: done.\n",
      "--glm linear regression on quantitative phenotypes #2401-2640: done.\n",
      "--glm linear regression on quantitative phenotypes #2641-2880: done.\n",
      "--glm linear regression on quantitative phenotypes #2881-3120: done.\n",
      "--glm linear regression on quantitative phenotypes #3121-3143: done.\n",
      "Results written to data/gwas/result.<phenotype name>.glm.linear.zst .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: All samples for --glm phenotype 'and_H15_F50' are cases.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time: Mon Nov 25 16:58:07 2024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['plink2', '--pfile', '../../data/geno/ukb_wb_subsampled', '--pheno', 'data/pheno/full_pheno.tsv', '--glm', 'zs', 'hide-covar', 'allow-no-covars', '--threads', '100', '--out', 'data/gwas/result'], returncode=7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"\n",
    "plink2 \\\n",
    "    --pfile ../../data/geno/ukb_wb_subsampled \\\n",
    "    --pheno data/pheno/full_pheno.tsv \\\n",
    "    --glm zs hide-covar allow-no-covars \\\n",
    "    --threads 100 \\\n",
    "    --out data/gwas/result\n",
    "\"\"\"\n",
    "subprocess.run(shlex.split(command))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf35db1-b344-4434-bbc5-e6cc1673e79b",
   "metadata": {},
   "source": [
    "# Gather GWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2762f01-abf3-45dd-98f2-126c9cf154f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pl.scan_csv(\"data/gwas/result*.zst\", separator=\"\\t\", glob=True, include_file_paths=\"path\")\n",
    "    .select(\n",
    "        pl.col(\"path\").str.strip_prefix(\"data/gwas/result.\").str.strip_suffix(\".glm.linear.zst\"),\n",
    "        \"ID\", \"BETA\", \"SE\",\n",
    "        (pl.col(\"BETA\") / pl.col(\"SE\")).pow(2).alias(\"CHISQ\"),\n",
    "    )\n",
    "    .sink_parquet(\"data/gwas/full_results.parquet\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
